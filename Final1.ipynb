{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2140\n"
     ]
    }
   ],
   "source": [
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "\n",
    "#initialization\n",
    "n = 200\n",
    "m = 230\n",
    "tau1 = 3\n",
    "tau2 = 1.5\n",
    "mu = 0.3\n",
    "\n",
    "pop1_belief = [0,0,0,0,0,0,0,0,0,0]\n",
    "pop2_belief = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "#Creating Population 1\n",
    "G1 = LFR_benchmark_graph(n, tau1, tau2, mu, average_degree=15, min_community=20, seed=10)\n",
    "nx.set_node_attributes(G1, 0,  name=\"beliefspace\")\n",
    "nx.set_node_attributes(G1, 1, name=\"Population\")\n",
    "nx.set_node_attributes(G1, 0, name=\"acceptance\")\n",
    "nx.set_edge_attributes(G1, 0, name=\"weight\")\n",
    "\n",
    "\n",
    "\n",
    "#Creating Population 2\n",
    "G2 = LFR_benchmark_graph(m, tau1, tau2, mu, average_degree=15, min_community=40, seed=10)\n",
    "nx.set_node_attributes(G2, 0 , name=\"beliefspace\")\n",
    "nx.set_node_attributes(G2, 2 , name=\"Population\")\n",
    "nx.set_node_attributes(G2, 0, name=\"acceptance\")\n",
    "nx.set_edge_attributes(G2, 0, name=\"weight\")\n",
    "\n",
    "\n",
    "#set belief space for individuals in Population 1 \n",
    "for i in G1.nodes:\n",
    "    G1.nodes[i]['beliefspace'] = np.random.randint(100, size = 10)\n",
    "    \n",
    "\n",
    "    \n",
    "#set accessibility for individuals in Population 1 \n",
    "for i in G1.nodes:\n",
    "    G1.nodes[i]['acceptance'] = np.random.randint(10,50)\n",
    "\n",
    "    \n",
    "\n",
    "#calculating normative knowledge for population 1\n",
    "for node in range(n):\n",
    "    pop1_belief += G1.nodes[node]['beliefspace']\n",
    "\n",
    "pop1_belief = (np.around((pop1_belief/n), 0)).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#attributes of population1\n",
    "G1.graph['beliefspace'] = pop1_belief\n",
    "G1.graph['Population'] = 1\n",
    "\n",
    "\n",
    "\n",
    "#set belief space for individuals in Population 2 \n",
    "for i in G2.nodes:\n",
    "    G2.nodes[i]['beliefspace'] = np.random.randint(-80, 20, size = 10)\n",
    "    \n",
    "#set belief space for a community in pop2\n",
    "# communities = {frozenset(G2.nodes[v][\"community\"]) for v in G2}\n",
    "\n",
    "# com_list = list(communities)\n",
    "\n",
    "# for i in com_list[2]:\n",
    "#     G2.nodes[i]['beliefspace'] = np.random.randint(100, size = 10)\n",
    "    \n",
    "\n",
    "    \n",
    "#set accessibility for individuals in Population 2 \n",
    "for i in G2.nodes:\n",
    "    G2.nodes[i]['acceptance'] = np.random.randint(10, 50)\n",
    "\n",
    "\n",
    "    \n",
    "#calculating normative knowledge for population2\n",
    "for node in range(m):\n",
    "    for item1 in range(10):\n",
    "        pop2_belief[item1] = pop2_belief[item1] + G2.nodes[node]['beliefspace'][item1]\n",
    "for item1 in range(10):\n",
    "    pop2_belief[item1] = np.around((pop2_belief[item1]/m), 0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#attributes of population2\n",
    "G2.graph['beliefspace'] = pop2_belief\n",
    "G2.graph['Population'] = 2\n",
    "\n",
    "\n",
    "\n",
    "#set edge weights \n",
    "Total_dis = 0\n",
    "\n",
    "\n",
    "def setWeight(G):\n",
    "    for i in G.nodes:\n",
    "        for x in G.edges(i):\n",
    "            k = 0   # k = coefficient\n",
    "            distance = 0 # abs(difference) of elements\n",
    "            Total_dis = 0\n",
    "            for j in range(10):\n",
    "                distance = abs(G.nodes[i]['beliefspace'][j] - G.nodes[x[1]]['beliefspace'][j])\n",
    "                if distance != 0:\n",
    "                    Total_dis += distance\n",
    "                    k = k+1\n",
    "                else:\n",
    "                    continue\n",
    "            G.edges[i, x[1]][\"weight\"] = (k*(Total_dis/100))/100\n",
    "            \n",
    "        \n",
    "setWeight(G1)    \n",
    "setWeight(G2)\n",
    "\n",
    "\n",
    "\n",
    "#G1 weights and sd\n",
    "list_of_weights1 = []\n",
    "pop1_weight = 0\n",
    "\n",
    "\n",
    "for i in G1.nodes:\n",
    "    for j in G1.neighbors(i):\n",
    "        pop1_weight += G1.get_edge_data(i, j).get('weight')\n",
    "        list_of_weights1.append(G1.get_edge_data(i, j).get('weight'))\n",
    "    \n",
    "pop1_weight = (pop1_weight/G1.number_of_edges())\n",
    "\n",
    "\n",
    "G1.graph['weight'] = pop1_weight\n",
    "G1.graph['sd'] = statistics.stdev(list_of_weights1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#G2 weights and sd\n",
    "list_of_weights2 = []\n",
    "pop2_weight = 0\n",
    "\n",
    "\n",
    "for i in G2.nodes:\n",
    "    for j in G2.neighbors(i):\n",
    "        pop2_weight += G2.get_edge_data(i, j).get('weight')\n",
    "        list_of_weights2.append(G2.get_edge_data(i, j).get('weight'))\n",
    "    \n",
    "pop2_weight = (pop2_weight/G2.number_of_edges())\n",
    "\n",
    "\n",
    "\n",
    "G2.graph['weight'] = pop2_weight\n",
    "G2.graph['sd'] = statistics.stdev(list_of_weights2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#writing node attributes of Population 1 \n",
    "with open(\"project/node_attr1.txt\", \"w\") as f:\n",
    "    for i in G1.nodes:\n",
    "        f.write(str(i) + \":\" + str(G1.nodes[i]['beliefspace']) + \":\" + str(G1.nodes[i]['acceptance']) + \"\\n\")\n",
    "        \n",
    "#writing graph 1 structure\n",
    "nx.write_edgelist(G1, \"project/graph1.edgelist\", data=[\"weight\"])   \n",
    "\n",
    "#writing graph 1 attribute  \n",
    "with open(\"project/graph1_attr.txt\", \"w\") as f:\n",
    "        f.write(str(G1.graph['beliefspace']) + \"\\n\")\n",
    "        f.write(str(G1.graph['weight']) + \"\\n\")\n",
    "        f.write(str(G1.graph['sd']) + \"\\n\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#writing node attributes of Population 2 \n",
    "with open(\"project/node_attr2.txt\", \"w\") as f:\n",
    "    for i in G2.nodes:\n",
    "        f.write(str(i) + \":\" + str(G2.nodes[i]['beliefspace']) + \":\" + str(G2.nodes[i]['acceptance']) + \"\\n\")\n",
    "        \n",
    "#writing graph 2 structure\n",
    "nx.write_edgelist(G2, \"project/graph2.edgelist\", data=[\"weight\"])    \n",
    "\n",
    "#writing graph 2 attribute  \n",
    "with open(\"project/graph2_attr.txt\", \"w\") as f:\n",
    "        f.write(str(G2.graph['beliefspace']) + \"\\n\")\n",
    "        f.write(str(G2.graph['weight']) + \"\\n\")\n",
    "        f.write(str(G2.graph['sd']) + \"\\n\")\n",
    "\n",
    "\n",
    "#print(com_list)  \n",
    "\n",
    "print(G2.number_of_edges())\n",
    "        \n",
    "# for i in G2.nodes:\n",
    "#     print(\"node\", i, \": \" , G2.nodes[i]['beliefspace'])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "communities = {frozenset(G2.nodes[v][\"community\"]) for v in G2}\n",
    "\n",
    "com_list = list(communities)\n",
    "\n",
    "print(len(com_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({0, 130, 3, 134, 10, 14, 15, 144, 18, 19, 149, 22, 151, 23, 26, 27, 156, 157, 29, 32, 35, 168, 40, 173, 47, 49, 50, 179, 52, 51, 182, 53, 185, 195, 75, 81, 99, 100, 104, 109, 115, 117, 121, 124, 126}), frozenset({129, 6, 7, 136, 137, 8, 139, 16, 24, 25, 155, 163, 44, 175, 54, 184, 56, 187, 62, 190, 191, 192, 193, 66, 65, 196, 68, 64, 63, 73, 77, 79, 80, 82, 83, 85, 86, 87, 88, 90, 91, 93, 98, 101, 102, 103, 105, 107, 113, 118, 120, 125}), frozenset({1, 2, 4, 5, 9, 11, 12, 13, 17, 20, 21, 28, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 48, 55, 57, 58, 59, 60, 61, 67, 69, 70, 71, 72, 74, 76, 78, 84, 89, 92, 94, 95, 96, 97, 106, 108, 110, 111, 112, 114, 116, 119, 122, 123, 127, 128, 131, 132, 133, 135, 138, 140, 141, 142, 143, 145, 146, 147, 148, 150, 152, 153, 154, 158, 159, 160, 161, 162, 164, 165, 166, 167, 169, 170, 171, 172, 174, 176, 177, 178, 180, 181, 183, 186, 188, 189, 194, 197, 198, 199})}\n"
     ]
    }
   ],
   "source": [
    "communities1 = {frozenset(G1.nodes[v][\"community\"]) for v in G1}\n",
    "print(communities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "com2_list = list(com_list[2])\n",
    "com3_list = list(com_list[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2dd11bd55804>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;31m# G2_weight update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         \u001b[0msetWeight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# G2 weights and sd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-2dd11bd55804>\u001b[0m in \u001b[0;36msetWeight\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'beliefspace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'beliefspace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                         \u001b[0mTotal_dis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "from random import choice\n",
    "from random import sample\n",
    "from shutil import copyfile\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os \n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "\n",
    "# n = 200\n",
    "# m = 500\n",
    "start_time = time.time()\n",
    "# initial setup\n",
    "\n",
    "\n",
    "df_distance_ave = pd.DataFrame()\n",
    "df_original_opinion = pd.DataFrame()\n",
    "it_new = []\n",
    "\n",
    "for experiment in range (50):\n",
    "    count_first=0\n",
    "    iteration_first=0\n",
    "    # Reading graph 1 structure\n",
    "    G1 =nx.read_weighted_edgelist(\"project/graph1.edgelist\", create_using = nx.Graph(), nodetype = int)\n",
    "    # Reading graph 2 structure\n",
    "    G2 =nx.read_weighted_edgelist(\"project/graph2.edgelist\", create_using = nx.Graph(), nodetype = int)\n",
    "\n",
    "    # Reading node attributes of Population 1\n",
    "    with open(\"project/node_attr1.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            a = []\n",
    "            line = line.split(':')\n",
    "            node = int(line[0])\n",
    "            belief1 = line[1]\n",
    "            acceptance= int(line[2])/100\n",
    "            removed = ''\n",
    "            for j in belief1:\n",
    "                if(j == '[' or j == ']'):\n",
    "                    continue\n",
    "                else:\n",
    "                    removed += j\n",
    "                new = removed.split()\n",
    "            for j in new:\n",
    "                x = int(j)\n",
    "                a.append(x)\n",
    "            results = np.array(a)\n",
    "            attrs = {\n",
    "                'beliefspace' : results,\n",
    "                'population' : 1,\n",
    "                'distance_in' : 0,\n",
    "                'distance_out' : 0,\n",
    "                'acceptance': acceptance\n",
    "            }\n",
    "            G1.add_node(node, **attrs)\n",
    "            \n",
    "            \n",
    "    \n",
    "           \n",
    "    # Reading graph 1 attribute\n",
    "    with open(\"project/graph1_attr.txt\") as fi:\n",
    "        lines = fi.readlines()\n",
    "        belief1 = lines[0]\n",
    "        new = []\n",
    "        a = []\n",
    "        removed2 = ''\n",
    "        for j in belief1:\n",
    "            if(j == '[' or j == ']'):\n",
    "                continue\n",
    "            else:\n",
    "                removed2 += j\n",
    "            new = removed2.split()\n",
    "        for j in new:\n",
    "            x = int(j)\n",
    "            a.append(x)\n",
    "        results2 = np.array(a)\n",
    "        G1.graph['beliefspace'] = results2\n",
    "        g1_weight = float(lines[1])\n",
    "        G1.graph['weight'] = g1_weight\n",
    "        g1_sd = float(lines[2])\n",
    "        G1.graph['sd'] = g1_sd\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # Reading node attributes of Population 2\n",
    "    with open(\"project/node_attr2.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            a = []\n",
    "            line = line.split(':')\n",
    "            node = int(line[0])\n",
    "            belief2 = line[1]\n",
    "            acceptance = int(line[2])/100\n",
    "            removed = ''\n",
    "            for j in belief2:\n",
    "                if(j == '[' or j == ']'):\n",
    "                    continue\n",
    "                else:\n",
    "                    removed += j\n",
    "                new = removed.split()\n",
    "            for j in new:\n",
    "                x = int(j)\n",
    "                a.append(x)\n",
    "            results = np.array(a)\n",
    "            attrs = {\n",
    "                'beliefspace' : results,\n",
    "                'population' : 2,\n",
    "                'distance_in' : 0,\n",
    "                'distance_out' : 0,\n",
    "                'acceptance': acceptance\n",
    "            }\n",
    "            G2.add_node(node, **attrs)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Reading graph 2 attribute\n",
    "    with open('project/graph2_attr.txt') as fi:\n",
    "        lines = fi.readlines()\n",
    "        belief1 = lines[0]\n",
    "        removed2 = []\n",
    "        belief1 = belief1.replace(\"[\", \"\")\n",
    "        new = belief1.replace(\"]\", \"\")\n",
    "        new = new.replace(\",\", \"\")\n",
    "        belief1 = new.split()\n",
    "        for j in belief1:\n",
    "            removed2.append(int (j))\n",
    "        results2 = np.array(removed2)\n",
    "        G2.graph['beliefspace'] = results2\n",
    "        g2_weight = float(lines[1])\n",
    "        G2.graph['weight'] = g2_weight\n",
    "        g2_sd = float(lines[2])\n",
    "        G2.graph['sd'] = g2_sd\n",
    "        \n",
    "     \n",
    "    \n",
    "   \n",
    "    #functions\n",
    "\n",
    "    def setWeight(G):\n",
    "        for i in G.nodes:\n",
    "            for x in G.edges(i):\n",
    "                k = 0  # k = coefficient\n",
    "                distance = 0  # abs(difference) of elements\n",
    "                Total_dis = 0\n",
    "                for j in range(10):\n",
    "                    distance = abs(G.nodes[i]['beliefspace'][j] - G.nodes[x[1]]['beliefspace'][j])\n",
    "                    if distance != 0:\n",
    "                        Total_dis += distance\n",
    "                        k = k + 1\n",
    "                    else:\n",
    "                        continue\n",
    "                G.edges[i, x[1]][\"weight\"] = (k * (Total_dis / 100)) / 100\n",
    "                \n",
    "         \n",
    "    \n",
    "    def takeSecond(elem):\n",
    "        return elem[1]\n",
    "\n",
    "\n",
    "    def sorting(n):\n",
    "        for i in G1.nodes:\n",
    "            if (n == G1):\n",
    "                y.append([i, G1.nodes[i].get('distance_in')])\n",
    "            if (n == G2):\n",
    "                y.append([i, G1.nodes[i].get('distance_out')])\n",
    "\n",
    "        y.sort(key=takeSecond)\n",
    "\n",
    "    #Create a list of 20 individuals for scenario 3 and 4\n",
    "    def create_list(numbers, rangee):\n",
    "        community_list = []\n",
    "        if (rangee == 0):\n",
    "            for i in range(numbers):\n",
    "                community_list.append(y[i][0])\n",
    "\n",
    "            ind = np.random.choice(community_list)\n",
    "            return ind\n",
    "        if (rangee == 1):\n",
    "            for i in range(n-20, n):\n",
    "                community_list.append(y[i][0])\n",
    "\n",
    "            ind = np.random.choice(community_list)\n",
    "            return ind\n",
    "\n",
    "    \n",
    "            \n",
    "    def distance_in(G):\n",
    "        for i in G.nodes:\n",
    "            k = 0  # k = coefficient\n",
    "            distance = 0  # abs(difference) of elements\n",
    "            Total_dis = 0\n",
    "            for j in range(10):\n",
    "                distance = abs(G.nodes[i]['beliefspace'][j] - G.graph['beliefspace'][j])\n",
    "                if distance != 0:\n",
    "                    Total_dis += distance\n",
    "                    k = k + 1\n",
    "                else:\n",
    "                    continue\n",
    "            G.nodes[i]['distance_in'] = k * (Total_dis / 100)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def distance_out(G, G_prime):\n",
    "        for i in G.nodes:\n",
    "            k = 0   # k = coefficient\n",
    "            distance = 0 # abs(difference) of elements\n",
    "            Total_dis = 0\n",
    "            for j in range(10):\n",
    "                distance = abs(G.nodes[i]['beliefspace'][j] - G_prime.graph['beliefspace'][j])\n",
    "                if distance != 0:\n",
    "                    Total_dis += distance\n",
    "                    k = k+ 1\n",
    "                else:\n",
    "                    continue\n",
    "            G.nodes[i]['distance_out'] = k * (Total_dis / 100)\n",
    "\n",
    "    \n",
    "    def dis_btw_inds(the_list):\n",
    "        list_of_dis = []\n",
    "        for ind in the_list:\n",
    "            k = 0  # k = coefficient\n",
    "            distance = 0  # abs(difference) of elements\n",
    "            Total_dis = 0\n",
    "            for j in range(10):\n",
    "                distance = abs(G2.nodes[migrated_individual]['beliefspace'][j] - G2.nodes[ind]['beliefspace'][j])\n",
    "                if distance != 0:\n",
    "                    Total_dis += distance\n",
    "                    k = k + 1\n",
    "            ind_dis = k * (Total_dis / 100)\n",
    "            list_of_dis.append([ind, ind_dis])\n",
    "        \n",
    "        return list_of_dis\n",
    "    \n",
    "\n",
    "    # selecting an individual\n",
    "    #scenario = int(input(\"Select an individual: \\n 1. Elite \\n 2. Random \\n 3. Similar to destination Population \\n 4. Isolated \\n\"))\n",
    "    \n",
    "    scenario=2\n",
    "    global y\n",
    "    y = []\n",
    "\n",
    "\n",
    "    individual = 0\n",
    "    distance_in(G1)\n",
    "    distance_in(G2)\n",
    "    distance_out(G1,G2)\n",
    "    distance_out(G2,G1)\n",
    "    setWeight(G1)\n",
    "    setWeight(G2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if (scenario == 1):\n",
    "        sorting(G1)\n",
    "        individual = create_list(20, 0)\n",
    "        \n",
    "    if (scenario == 2):\n",
    "        individual = np.random.randint(0, G1.number_of_nodes())\n",
    "\n",
    "    if (scenario == 3):\n",
    "        sorting(G2)\n",
    "        individual = create_list(20, 0)\n",
    "        \n",
    "    if (scenario == 4):\n",
    "        sorting(G1)\n",
    "        individual = create_list(0, 1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # migration\n",
    "    Belief = G1.nodes[individual][\"beliefspace\"]\n",
    "    Pop_flag = G1.nodes[individual][\"population\"]\n",
    "    acceptance_1= G1.nodes[individual][\"acceptance\"]\n",
    "    \n",
    "    migrated_individual = G2.number_of_nodes()\n",
    "\n",
    "    G2.add_node(migrated_individual, beliefspace=Belief, population=Pop_flag, acceptance= acceptance_1, distance_out=0, distance_in=0)\n",
    "    \n",
    "    original_belief = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(10):\n",
    "        original_belief[i] = G2.nodes[migrated_individual]['beliefspace'][i]\n",
    "    \n",
    "    \n",
    "    def original_opinion():\n",
    "            k = 0  # k = coefficient\n",
    "            distance = 0  # abs(difference) of elements\n",
    "            Total_dis = 0\n",
    "            for j in range(10):\n",
    "                distance = abs(G2.nodes[migrated_individual]['beliefspace'][j] - original_belief[j])\n",
    "                if distance != 0:\n",
    "                    Total_dis += distance\n",
    "                    k = k + 1\n",
    "            dis = k * (Total_dis / 10)\n",
    "            return dis\n",
    "        \n",
    "        \n",
    "    #Finding the best community to connect to\n",
    "    com2_dis = dis_btw_inds(com2_list)\n",
    "    com3_dis = dis_btw_inds(com3_list)\n",
    "    \n",
    "    \n",
    "    sum2 = 0\n",
    "    sum3 = 0\n",
    "    \n",
    "    \n",
    "    for i,j in com2_dis:\n",
    "        sum2 += j \n",
    "    ave2 = (sum2/len(com2_dis))\n",
    "    \n",
    "    \n",
    "    for i,j in com3_dis:\n",
    "        sum3 += j \n",
    "    ave3 = (sum3/len(com3_dis))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # option 1 : Random\n",
    "    \n",
    "#     selected_ind = np.random.randint(0,(G2.number_of_nodes()-1))\n",
    "#     G2.add_edge(migrated_individual, selected_ind)\n",
    "#     setWeight(G2)\n",
    "    \n",
    "    \n",
    "    # option 2 : connect to the most similar person\n",
    "    \n",
    "#     x_list = np.random.randint(0, G2.number_of_nodes() - 1, 23)\n",
    "#     list_of_dis = []\n",
    "#     list_of_dis = dis_btw_inds(x_list)\n",
    "#     list_of_dis.sort(key=takeSecond)\n",
    "#     selected_ind = list_of_dis[0][0]\n",
    "#     G2.add_edge(migrated_individual, selected_ind)\n",
    "#     setWeight(G2)\n",
    "    \n",
    "    # option 3 : connect to a community           \n",
    "        \n",
    "    if( ave2 < ave3):\n",
    "        for i in range(3):\n",
    "            selected_ind = np.random.choice(com2_list)\n",
    "            G2.add_edge(migrated_individual, selected_ind)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        for i in range(3):\n",
    "            selected_ind = np.random.choice(com3_list)\n",
    "            G2.add_edge(migrated_individual, selected_ind)\n",
    "            \n",
    "        \n",
    "    G2.add_edge(migrated_individual, selected_ind)\n",
    "    setWeight(G2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # copying previous files\n",
    "    file_name = str(experiment) \n",
    "    file_address=\"project/copy/files/\" \n",
    "    \n",
    "    copyfile(\"project/node_attr1.txt\", file_address + file_name + \"_node_attr1_copy.txt\")\n",
    "    copyfile(\"project/graph1.edgelist\", file_address + file_name + \"_graph1_copy.edgelist\")\n",
    "    copyfile(\"project/graph1_attr.txt\", file_address + file_name + \"_graph1_attr_copy.txt\")\n",
    "\n",
    "    copyfile(\"project/node_attr2.txt\", file_address + file_name + \"_node_attr2_copy.txt\")\n",
    "    copyfile(\"project/graph2.edgelist\", file_address + file_name + \"_graph2_copy.edgelist\")\n",
    "    copyfile(\"project/graph2_attr.txt\", file_address + file_name + \"_graph2_attr_copy.txt\")\n",
    "\n",
    "    # adding new edge to file\n",
    "    new_node_to_string = str(migrated_individual)\n",
    "    selected_to_string = str(selected_ind)\n",
    "    weights = str(G2.edges[migrated_individual, selected_ind]['weight'])\n",
    "\n",
    "    with open(file_address + file_name + \"_graph2_copy.edgelist\", 'a') as f:\n",
    "        f.write(new_node_to_string + \" \" + selected_to_string + \" \" + weights + \"\\n\")\n",
    "\n",
    "    # adding new node attribute to file\n",
    "    with open(file_address + file_name + \"_node_attr2_copy.txt\", 'a') as f:\n",
    "        f.write(\"--------------------migration------------------\" + \"\\n\")\n",
    "        f.write(new_node_to_string + \":\" + str(G2.nodes[migrated_individual]['beliefspace']) + \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "    distance_in(G1)\n",
    "    distance_in(G2)\n",
    "    distance_out(G1,G2)\n",
    "    distance_out(G2,G1)\n",
    "    \n",
    "    \n",
    "    #creating a list of nodes for comparison\n",
    "    major_node = migrated_individual\n",
    "    selected = selected_ind\n",
    "    nodes = [major_node, selected]\n",
    "    \n",
    "    while( len(nodes) < 22 ):\n",
    "        node = np.random.randint(0, G2.number_of_nodes()-1)\n",
    "        if( node != selected ):\n",
    "            nodes.append(node)\n",
    "            \n",
    "    #original_beliefs = []\n",
    "    #for node in nodes:\n",
    "    #    original_beliefs.append((node, G2.nodes[node]['beliefspace']))\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    G2_belief = G2.graph['beliefspace']\n",
    "    \n",
    "    df_list = []\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final2 = pd.DataFrame()\n",
    "    final_list = []\n",
    "    migrant_dis = []\n",
    "    rest_dis = []\n",
    "    final_sd = []\n",
    "    original = []\n",
    "    done = 0\n",
    "    \n",
    "    \n",
    "    df_weight = pd.DataFrame(columns=['iteration', 'node', 'average_weight', 'sd'])\n",
    "    df_distance = pd.DataFrame(columns=nodes)\n",
    "    df_friends = pd.DataFrame(columns=nodes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # start of iterations\n",
    "    # i = 1\n",
    "    for iteration in range(50):\n",
    "        \n",
    "        pop2_belief = [0,0,0,0,0,0,0,0,0,0]\n",
    "        list_of_friends = []\n",
    "        fr = []\n",
    "        z = 0\n",
    "        df_col0 = []\n",
    "        df_col1 = []\n",
    "        df_col2 = []\n",
    "        df_col3 = []\n",
    "        df_final = pd.DataFrame()\n",
    "        df = pd.DataFrame()\n",
    "       \n",
    "        \n",
    "\n",
    "        \n",
    "        # belief spaces change\n",
    "        for i in G2.nodes:\n",
    "            acceptance_rate = G2.nodes[i]['acceptance']\n",
    "            talk_prob = np.random.rand()\n",
    "            for j in G2.neighbors(i):\n",
    "                number_of_friends = 0\n",
    "                sum_of_friends = 0\n",
    "                if (talk_prob <= G2.get_edge_data(i, j).get('weight')):\n",
    "                    talk = 1\n",
    "                else:\n",
    "                    talk = 0\n",
    "                if (talk == 1):\n",
    "                    item = np.random.randint(0, 10)\n",
    "                    if (np.random.rand()<= acceptance_rate):\n",
    "                            Norm_graph2= G2.graph['beliefspace'][item] * (1 - (G2.nodes[i]['distance_in'] / 100))\n",
    "                            Friend_belief= G2.nodes[j]['beliefspace'][item] * (1 - G2.get_edge_data(i, j).get('weight'))\n",
    "                            opinion= G2.nodes[i]['beliefspace'][item]\n",
    "                            if (i==migrated_individual):\n",
    "                                    Norm_graph1 = G1.graph['beliefspace'][item] * (1 - (G2.nodes[i]['distance_out'] / 100))\n",
    "                                    G2.nodes[i]['beliefspace'][item] = (((1- acceptance_rate) * opinion) + ((acceptance_rate) * ((Norm_graph1 + ((Norm_graph2 + Friend_belief)/2))/2)))\n",
    "                            else:\n",
    "                                    G2.nodes[i]['beliefspace'][item] = (((1- acceptance_rate) * opinion) + ((acceptance_rate) * ((Norm_graph2 + Friend_belief)/2)))\n",
    "\n",
    "\n",
    "        # G2 changes\n",
    "        for node in range(G2.number_of_nodes()):\n",
    "            for item1 in range(10):\n",
    "                pop2_belief[item1] = pop2_belief[item1] + G2.nodes[node]['beliefspace'][item1]\n",
    "        for item1 in range(10):\n",
    "            pop2_belief[item1] = np.around((pop2_belief[item1] / G2.number_of_nodes()), 0).astype(int)\n",
    "        G2.graph['beliefspace'] = pop2_belief\n",
    "        \n",
    "\n",
    "        # distance_in and out change\n",
    "        distance_in(G2)\n",
    "        distance_out(G2,G1)\n",
    "        \n",
    "\n",
    "        # G2_weight update\n",
    "        setWeight(G2)\n",
    "\n",
    "        # G2 weights and sd\n",
    "        pop2_weight = 0\n",
    "        list_of_weights2 = []\n",
    "\n",
    "        for i in G2.nodes:\n",
    "            for j in G2.neighbors(i):\n",
    "                pop2_weight += G2.get_edge_data(i, j).get('weight')\n",
    "                list_of_weights2.append(G2.get_edge_data(i, j).get('weight'))\n",
    "\n",
    "        pop2_weight = (pop2_weight / G2.number_of_edges())\n",
    "        G2.graph['weight'] = pop2_weight\n",
    "        G2.graph['sd'] = statistics.stdev(list_of_weights2)\n",
    "\n",
    "    \n",
    "        # finding new friends\n",
    "        for x in G2.neighbors(migrated_individual):\n",
    "            for friend in G2.neighbors(x):\n",
    "                if (friend != migrated_individual and friend not in fr):\n",
    "                    k2 = 0  # k = coefficient\n",
    "                    distance2 = 0  # abs(difference) of elements\n",
    "                    friends_dis = 0\n",
    "                    dis_friends_of_friends = 0\n",
    "                    for j in range(10):\n",
    "                        distance2 = abs(G2.nodes[migrated_individual]['beliefspace'][j] - G2.nodes[friend]['beliefspace'][j])\n",
    "                        if distance2 != 0:\n",
    "                            friends_dis += distance2\n",
    "                            k2 = (k2) + 1\n",
    "                    weight_friends_of_friends = ((k2) * (friends_dis / 100)) / 100\n",
    "                    if (weight_friends_of_friends <= G2.edges[migrated_individual, x]['weight']):\n",
    "                        if (np.random.rand() < G2.edges[migrated_individual, x]['weight']):\n",
    "                            another = (friend, weight_friends_of_friends)\n",
    "                            another = list(another)\n",
    "                            list_of_friends.append(another)\n",
    "                            fr.append(friend)\n",
    "        \n",
    "        \n",
    "        # adding new friends\n",
    "        if len(list_of_friends) != 0 :\n",
    "            selected_friend= np.random.randint(0, len(list_of_friends))\n",
    "            G2.add_edge(migrated_individual, list_of_friends[selected_friend][0], weight=list_of_friends[selected_friend][1])\n",
    "                \n",
    "                \n",
    "        \n",
    "        #appending new edgelist (weights)\n",
    "        with open(file_address + file_name + \"_graph2_copy.edgelist\", 'a') as f:\n",
    "            f.write(\"-----------------iteration\" + str(iteration) + \"---------------------\" + \"\\n\")\n",
    "            for node in G2.nodes:\n",
    "                for neighbor in G2.neighbors(node):\n",
    "                    w = G2.get_edge_data(node, neighbor).get('weight')\n",
    "                    f.write(str(node) + \" \" + str(neighbor) + \" \" + str(w) + \"\\n\" )\n",
    "        \n",
    "        \n",
    "        #appending new attributes\n",
    "        with open(file_address + file_name + \"_node_attr2_copy.txt\", \"a\") as f:\n",
    "            f.write(\"-----------------iteration\" + str(iteration) + \"---------------------\" + \"\\n\")\n",
    "            for i in G2.nodes:\n",
    "                f.write(str(i) + \":\" + str(G2.nodes[i]['beliefspace']) + \"\\n\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # appending random node attributes, migrant attribute and G2 belief space after change\n",
    "        with open(file_address + file_name + \".txt\", 'a') as f:\n",
    "                    f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "                    for node in nodes:\n",
    "                        if (node == migrated_individual):\n",
    "                            text = str(node) + \" : \" + str(G2.nodes[node]['beliefspace']) + \" , \" + \"distance_in : \" + str(\n",
    "                                G2.nodes[node]['distance_in']) + \"\\n \\n\" + str(list_of_friends) + \"\\n \\n\"\n",
    "                        else:\n",
    "                            text = str(node) + \" : \" + str(G2.nodes[node]['beliefspace']) + \" , \" + \"distance_in : \" + str(\n",
    "                                G2.nodes[node]['distance_in']) + \"\\n \\n\"\n",
    "                        f.write(text)\n",
    "                    f.write(\"G2_belief space\" + str(G2.graph['beliefspace']) + \" , \" + \"AVE-weight : \" + str(\n",
    "                        G2.graph['weight']) + \" , \" + \"sd : \" + str(G2.graph['sd']) + \"\\n \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #scenario1\n",
    "        with open(file_address  + file_name + \"_new_friend.txt\", 'a') as f:\n",
    "            #print(list(G2.neighbors(migrated_individual)))\n",
    "            #print(len(list(G2.neighbors(migrated_individual))))\n",
    "            if(done == 0): \n",
    "                if(len(list(G2.neighbors(migrated_individual))) ==  2):\n",
    "                    it_new.append(iteration+1)\n",
    "                    done = 1\n",
    "                if(iteration == 49 and len(list(G2.neighbors(migrated_individual))) ==  1):\n",
    "                    it_new.append(0)\n",
    "                    \n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        #scenario2\n",
    "        with open(file_address + file_name + \"_weight.txt\", 'a') as f:\n",
    "            f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "            for node in nodes:\n",
    "                node_weight_info = []\n",
    "                weight_list = []\n",
    "                total_weight = 0\n",
    "                for neighbor in G2.neighbors(node):\n",
    "                    f.write(str(node) + \",\" + str(neighbor) + \" : \" + str(G2.edges[node,neighbor]['weight']) + \"\\n\")\n",
    "                    total_weight += G2.edges[node,neighbor]['weight']\n",
    "                    weight_list.append(G2.edges[node,neighbor]['weight'])\n",
    "                ave_weight = total_weight/len(list(G2.neighbors(node)))\n",
    "                if( len(weight_list) > 1):\n",
    "                    sd = statistics.stdev(weight_list)\n",
    "                else:\n",
    "                    sd = 0\n",
    "                node_weight_info = [iteration, node, ave_weight, sd]\n",
    "                df_weight.loc[len(df_weight), :] =  node_weight_info\n",
    "                         \n",
    "            f.write(\"\\n \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #scenario3\n",
    "        dis_row_list = []\n",
    "        \n",
    "        with open(file_address + file_name + \"_dis.txt\", 'a') as f:\n",
    "            f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "            for node in nodes:\n",
    "                dis_row_list.append(G2.nodes[node]['distance_in'])\n",
    "                f.write(str(node) + \" : \" + str(G2.nodes[node]['distance_in']) + \"\\n \\n\")\n",
    "                \n",
    "            df_distance.loc[len(df_distance), :] = dis_row_list\n",
    "            \n",
    "        \n",
    "        rest_ave = 0\n",
    "        standard_deviation = []\n",
    "        #with open(file_address + file_name + \"_dis_ave.txt\", 'a') as f:\n",
    "            #f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "        for node in nodes:\n",
    "            if(node == m):\n",
    "                migrant_dis.append(G2.nodes[migrated_individual]['distance_in'])\n",
    "            if(node != m):\n",
    "                rest_ave += G2.nodes[node]['distance_in']\n",
    "                standard_deviation.append(G2.nodes[node]['distance_in'])\n",
    "        rest_ave = rest_ave/(len(nodes) - 1)\n",
    "        rest_dis.append(rest_ave)\n",
    "        s_d = statistics.stdev(standard_deviation)\n",
    "        final_sd.append(s_d)\n",
    "        \n",
    "#         with open(file_address + file_name + \"_yo.txt\", 'a') as f:\n",
    "#             f.write(str(migrant_dis) + \"-------------\" + str(rest_dis))\n",
    "            \n",
    "            \n",
    "            \n",
    "        #scenario4\n",
    "        new_fr_list = []\n",
    "        with open(file_address + file_name + \"_friends.txt\", 'a') as f:\n",
    "            f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "            for node in nodes:\n",
    "                    new_fr_list.append(len(list(G2.neighbors(node))))\n",
    "                    f.write(str(node) + \" : \" + str(len(list(G2.neighbors(node)))) + \"\\n \\n\")\n",
    "            df_friends.loc[len(df_friends), :] = new_fr_list\n",
    "            \n",
    "           \n",
    "        \n",
    "        \n",
    "        #scenario5\n",
    "        #with open(file_address + file_name + \"_original.txt\", 'a') as f:\n",
    "        #f.write(\"-----------------iteration\" + str(iteration + 1) + \"---------------------\" + \"\\n \\n\")\n",
    "        original.append(original_opinion())\n",
    "        \n",
    "    \n",
    "    #print(experiment , it_new)\n",
    "    next_df_original_opinion = pd.DataFrame({ \"dis_to_original\": original})\n",
    "    \n",
    "    \n",
    "            \n",
    "    next_df_distance_ave = pd.DataFrame({ \"migrant\": migrant_dis,\n",
    "                        \"rest\":rest_dis,\n",
    "                        \"sd\": final_sd})\n",
    "    \n",
    "    \n",
    "        \n",
    "    df_distance_ave = pd.concat([df_distance_ave, next_df_distance_ave], axis = 1)\n",
    "    \n",
    "    df_original_opinion = pd.concat([df_original_opinion, next_df_original_opinion], axis = 1)\n",
    "        \n",
    "    df_weight.to_csv(file_address + file_name + '_weight.csv')\n",
    "    df_distance.to_csv(file_address + file_name + '_dis.csv')\n",
    "    \n",
    "    df_friends.to_csv(file_address + file_name + '_friends.csv')\n",
    "    \n",
    "df_distance_ave.to_csv(file_address + file_name + '_dis_ave.csv')\n",
    "df_original_opinion.to_csv(file_address + file_name + '_original.csv')\n",
    "df_new_fr = pd.DataFrame({\"new_connection_it\": it_new })\n",
    "\n",
    "df_new_fr.to_csv(file_address + file_name + '_new_connection.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "with open(file_address + file_name + \"time.txt\", \"w\") as f:\n",
    "    f.write(str(\"--- %s seconds ---\" % (time.time() - start_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggg\n",
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"fggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggg\")\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "with open(\"project/copy/files/t.txt\", \"w\") as f:\n",
    "    f.write(str(\"--- %s seconds ---\" % (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 45.7],\n",
       " [1, 37.3],\n",
       " [5, 43.2],\n",
       " [6, 36.800000000000004],\n",
       " [7, 28.1],\n",
       " [11, 24.900000000000002],\n",
       " [14, 35.2],\n",
       " [16, 27.7],\n",
       " [18, 42.1],\n",
       " [19, 39.4],\n",
       " [26, 32.400000000000006],\n",
       " [27, 28.700000000000003],\n",
       " [28, 33.1],\n",
       " [31, 31.9],\n",
       " [33, 43.5],\n",
       " [34, 32.8],\n",
       " [35, 41.900000000000006],\n",
       " [37, 28.900000000000002],\n",
       " [38, 32.0],\n",
       " [39, 35.6],\n",
       " [40, 45.300000000000004],\n",
       " [41, 31.9],\n",
       " [43, 38.3],\n",
       " [45, 32.9],\n",
       " [46, 24.900000000000002],\n",
       " [47, 35.8],\n",
       " [48, 29.3],\n",
       " [49, 31.400000000000002],\n",
       " [50, 28.1],\n",
       " [51, 25.9],\n",
       " [52, 29.6],\n",
       " [53, 32.400000000000006],\n",
       " [54, 32.599999999999994],\n",
       " [55, 32.2],\n",
       " [57, 42.9],\n",
       " [59, 31.7],\n",
       " [60, 29.1],\n",
       " [61, 30.7],\n",
       " [62, 31.9],\n",
       " [63, 31.5],\n",
       " [64, 34.2],\n",
       " [65, 43.3],\n",
       " [66, 28.4],\n",
       " [68, 35.4],\n",
       " [70, 34.6],\n",
       " [71, 29.700000000000003],\n",
       " [72, 29.900000000000002],\n",
       " [73, 40.099999999999994],\n",
       " [74, 28.1],\n",
       " [75, 33.5],\n",
       " [76, 36.1],\n",
       " [77, 30.4],\n",
       " [78, 32.5],\n",
       " [79, 29.1],\n",
       " [80, 31.8],\n",
       " [83, 31.9],\n",
       " [84, 29.8],\n",
       " [85, 25.4],\n",
       " [87, 31.299999999999997],\n",
       " [88, 34.7],\n",
       " [89, 42.9],\n",
       " [90, 32.5],\n",
       " [91, 33.7],\n",
       " [92, 30.8],\n",
       " [93, 34.0],\n",
       " [94, 31.6],\n",
       " [95, 29.43],\n",
       " [100, 33.3],\n",
       " [103, 36.2],\n",
       " [104, 37.9],\n",
       " [105, 40.099999999999994],\n",
       " [106, 33.7],\n",
       " [107, 26.299999999999997],\n",
       " [108, 31.200000000000003],\n",
       " [111, 30.0],\n",
       " [112, 32.7],\n",
       " [113, 33.9],\n",
       " [114, 38.199999999999996],\n",
       " [117, 30.5],\n",
       " [120, 26.8],\n",
       " [121, 38.0],\n",
       " [122, 32.3],\n",
       " [123, 26.0],\n",
       " [125, 29.5],\n",
       " [127, 34.2],\n",
       " [132, 44.3],\n",
       " [133, 33.199999999999996],\n",
       " [138, 37.5],\n",
       " [139, 33.5],\n",
       " [142, 41.6],\n",
       " [145, 33.8],\n",
       " [146, 29.6],\n",
       " [148, 30.6],\n",
       " [150, 32.85],\n",
       " [152, 37.9],\n",
       " [154, 31.5],\n",
       " [155, 38.0],\n",
       " [159, 29.900000000000002],\n",
       " [160, 28.599999999999998],\n",
       " [162, 36.800000000000004],\n",
       " [164, 31.099999999999998],\n",
       " [166, 30.06],\n",
       " [167, 32.1],\n",
       " [168, 39.8],\n",
       " [169, 28.900000000000002],\n",
       " [170, 37.9],\n",
       " [173, 28.700000000000003],\n",
       " [175, 38.9],\n",
       " [176, 30.4],\n",
       " [177, 35.5],\n",
       " [179, 31.400000000000002],\n",
       " [186, 26.9],\n",
       " [187, 32.5],\n",
       " [190, 32.0],\n",
       " [192, 31.200000000000003],\n",
       " [195, 30.2],\n",
       " [196, 35.099999999999994],\n",
       " [200, 25.099999999999998],\n",
       " [203, 44.2],\n",
       " [204, 30.0],\n",
       " [207, 31.5],\n",
       " [209, 35.0],\n",
       " [211, 31.5],\n",
       " [212, 37.0],\n",
       " [214, 30.9],\n",
       " [215, 37.5],\n",
       " [216, 31.0],\n",
       " [218, 29.4],\n",
       " [220, 29.5],\n",
       " [221, 33.9],\n",
       " [222, 38.5],\n",
       " [224, 34.4]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = dis_btw_inds(com2_list)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.31242424242423\n"
     ]
    }
   ],
   "source": [
    "sum2 = 0\n",
    "\n",
    "for i,j in p:\n",
    "    sum2 += j \n",
    "ave2 = (sum2/len(p))\n",
    "\n",
    "print(ave2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dis_btw_inds(com1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 38.9],\n",
       " [3, 30.4],\n",
       " [4, 30.0],\n",
       " [8, 32.1],\n",
       " [9, 24.39],\n",
       " [10, 34.8],\n",
       " [12, 35.6],\n",
       " [13, 29.1],\n",
       " [15, 28.700000000000003],\n",
       " [17, 29.900000000000002],\n",
       " [20, 37.8],\n",
       " [21, 28.2],\n",
       " [22, 32.49],\n",
       " [23, 31.86],\n",
       " [24, 49.400000000000006],\n",
       " [25, 41.8],\n",
       " [29, 34.8],\n",
       " [30, 44.5],\n",
       " [32, 37.5],\n",
       " [36, 35.699999999999996],\n",
       " [42, 34.300000000000004],\n",
       " [44, 35.0],\n",
       " [56, 40.099999999999994],\n",
       " [58, 29.79],\n",
       " [67, 36.4],\n",
       " [69, 28.700000000000003],\n",
       " [81, 32.1],\n",
       " [82, 51.7],\n",
       " [86, 28.700000000000003],\n",
       " [96, 33.8],\n",
       " [97, 29.700000000000003],\n",
       " [98, 34.300000000000004],\n",
       " [99, 31.8],\n",
       " [101, 24.660000000000004],\n",
       " [102, 35.9],\n",
       " [109, 34.4],\n",
       " [110, 28.2],\n",
       " [115, 29.4],\n",
       " [116, 31.400000000000002],\n",
       " [118, 31.7],\n",
       " [119, 34.1],\n",
       " [124, 30.299999999999997],\n",
       " [126, 27.799999999999997],\n",
       " [128, 29.900000000000002],\n",
       " [129, 38.6],\n",
       " [130, 27.5],\n",
       " [131, 36.9],\n",
       " [134, 30.5],\n",
       " [135, 34.1],\n",
       " [136, 36.0],\n",
       " [137, 30.330000000000002],\n",
       " [140, 31.299999999999997],\n",
       " [141, 29.2],\n",
       " [143, 36.9],\n",
       " [144, 28.44],\n",
       " [147, 30.4],\n",
       " [149, 27.799999999999997],\n",
       " [151, 43.2],\n",
       " [153, 35.9],\n",
       " [156, 33.6],\n",
       " [157, 51.7],\n",
       " [158, 29.700000000000003],\n",
       " [161, 30.2],\n",
       " [163, 37.1],\n",
       " [165, 33.7],\n",
       " [171, 30.099999999999998],\n",
       " [172, 29.0],\n",
       " [174, 29.5],\n",
       " [178, 29.1],\n",
       " [180, 38.9],\n",
       " [181, 32.400000000000006],\n",
       " [182, 28.4],\n",
       " [183, 28.2],\n",
       " [184, 39.900000000000006],\n",
       " [185, 35.699999999999996],\n",
       " [188, 34.8],\n",
       " [189, 40.599999999999994],\n",
       " [191, 39.1],\n",
       " [193, 32.2],\n",
       " [194, 32.7],\n",
       " [197, 33.3],\n",
       " [198, 30.5],\n",
       " [199, 34.300000000000004],\n",
       " [201, 34.300000000000004],\n",
       " [202, 41.0],\n",
       " [205, 31.0],\n",
       " [206, 28.700000000000003],\n",
       " [208, 33.7],\n",
       " [210, 40.300000000000004],\n",
       " [213, 28.3],\n",
       " [217, 33.4],\n",
       " [219, 31.8],\n",
       " [223, 39.4],\n",
       " [225, 30.7],\n",
       " [226, 39.300000000000004],\n",
       " [227, 37.599999999999994],\n",
       " [228, 31.7],\n",
       " [229, 35.6]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
